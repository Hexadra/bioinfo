## Homework 11        
### IV.3.Machine Learning with Python             
作业副本另见[my Github homework 11](https://github.com/Hexadra/bioinfo/blob/main/HW/hw11.md)      
#### 1. 我们提供了一个qPCR数据集qPCR_data.csv，第1列为sample id，第2-12列为特征(11个基因的表达量)，第13列为样本标签(负例为健康人:NC,正例为肝癌病人:HCC)。请大家完成以下任务，提交代码，必要的文字解释，数据可视化结果及ROC曲线：         
       
代码全文及注释见本markdown文件最后。PCA可视化结果及ROC曲线见下：     
![hw11PCA](https://github.com/Hexadra/bioinfo/assets/126166219/8561f986-c700-4103-884f-c15b6fac8d67)     
PCA可视化结果     
![hw11ROC](https://github.com/Hexadra/bioinfo/assets/126166219/58d94ec7-76a4-4f53-9f25-5e5b83122b49)      
ROC曲线      
       
        
#### 2. 随机森林是生物信息经常使用的一个分类器。请大家查阅资料，回答以下两个问题:          
1) 随机森林中树的数量是不是一个需要通过交叉验证调整的超参数?为什么?       
          
随机森林中树的数量不需要交叉验证，因为      
     
       
2) 请问什么是随机森林的out-of-bag (OOB) error?它和bootstrapping有什么关系?      
         
随机森林在构建每棵树时都采用bootstrapping采样，所以对于每棵树而言，会有一部分样本没有参与这棵树的构建。        
对于一个样本，如果其没有参与选择的树的构建，则计算这棵树对这个样本的分类情况；对所有该样本未参与的树计算得到的结果进行统计，用简单多数投票决定该样本属于哪一类别。    
对每个样本都进行如上述的计算，最后计算所有样本中误分类的比率，即为随机森林的OOB error。        
     
         
以下是作业1的代码全文：     
```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
from sklearn.decomposition import PCA
from sklearn.feature_selection import RFECV
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve,auc

# 加载数据
data = pd.read_csv('qPCR_data.csv',sep='\t',index_col=0)
label_lut = pd.Series({"NC":0,"HCC":1})
y = label_lut.loc[data["label"]].values # 将样本标签由字符串转化为整数表示
data = data.iloc[:,:-1] #选取feature对应列
data = data.fillna(data.mean(axis=0)) #用均值填充缺失值
X = StandardScaler().fit_transform(data.values) # Z score scaling


# 用PCA可视化
X2d = PCA(2).fit_transform(X)
fig, ax = plt.subplots(figsize=(4.5,4))
for i in range(3):
    plt.scatter(X2d[y==i,0],X2d[y==i,1])#label=names[i]
ax.set_xlabel("PC1")
ax.set_ylabel("PC2")
plt.legend()
plt.show()
plt.savefig("hw11_PCA_plot.png",bbox_inches="tight")


# 划分数据集
X_discovery, X_validation, y_discovery, y_validation = train_test_split(X, y, test_size=0.2, random_state=666)
print(f"{X_discovery.shape[0]} samples in discovery set")
print(f"{X_validation.shape[0]} samples in validation set")


# 使用RFECV
clf = GridSearchCV(LogisticRegression(penalty="l2"),
                   param_grid={"C":[0.01,0.1,1,10]}, cv=5,
                   scoring="roc_auc",refit=True,verbose=4)
selector = RFECV(clf, step=1, 
                 min_features_to_select=3,cv=5,
                 importance_getter=lambda clf:clf.best_estimator_.coef_,
                 scoring="roc_auc",verbose=4)
selector = selector.fit(X_discovery, y_discovery)
#print(selector.support_)
#print(selector.ranking_)


# 枚举特征组合 并传递超参
from itertools import combinations
feature_combinations=[]
for i in combinations(list(range(9)), 3):
    feature_combinations.append(list(i))
print(len(feature_combinations))

from sklearn.base import ClassifierMixin, BaseEstimator
class MaskedLogisticRegression(BaseEstimator, ClassifierMixin):
    def __init__(self,feature_indices=None,**params):
        self.feature_indices = feature_indices
        self.estimator = LogisticRegression(**params)
    def mask(self,X):
        if self.feature_indices is None: return X
        else: return X[:,self.feature_indices]
    def fit(self, X, y=None):
        self.classes_ = np.unique(y)
        return self.estimator.fit(self.mask(X),y)
    def predict(self, X):
        return self.estimator.predict(self.mask(X))
    def predict_proba(self, X):
        return self.estimator.predict_proba(self.mask(X))
        


# 用GridSearchCV评估每个特征组合的性能
clf = GridSearchCV(MaskedLogisticRegression(),
                   param_grid={"feature_indices":feature_combinations}, cv=5,
                   scoring="roc_auc",refit=True,verbose=4)
clf = clf.fit(X_discovery, y_discovery)
# print(list(data.columns[clf.best_params_['feature_indices']]))


# 计算AUROC 并绘制曲线
y_pred_proba = clf.predict_proba(X_validation)[:,1]
fpr, tpr,_ = roc_curve(y_validation,y_pred_proba)
AUROC = auc(fpr, tpr)

plt.figure(figsize=(4,4))
plt.plot(fpr, tpr, '-', color='b', label='Validation AUC of {:.4f}'.format(AUROC), lw=2)
plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random Chance')
plt.xlim([-0.01, 1.01])
plt.ylim([-0.01, 1.01])
plt.title('ROC curve of test data')
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.legend(loc='best',fontsize='small')
plt.tight_layout()
plt.show()
plt.close()
```
